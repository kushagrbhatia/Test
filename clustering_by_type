import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.decomposition import PCA

# 1. Load your dataset (replace with actual dataset location)
df = pd.read_csv("your_data.csv")

# 2. Preprocessing: One-hot encode 'ClusterType' and scale 'RunningVMs'
X = df[['ClusterType', 'RunningVMs']]

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['RunningVMs']),
        ('cat', OneHotEncoder(), ['ClusterType'])  # One-hot encoding the categorical data
    ])

X_preprocessed = preprocessor.fit_transform(X)

# 3. Determine optimal number of clusters using the Elbow method
inertia = []
K = range(1, 11)

for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_preprocessed)
    inertia.append(kmeans.inertia_)

# Plot Elbow Graph
plt.figure(figsize=(8, 4))
plt.plot(K, inertia, 'bo-', markersize=8)
plt.title('Elbow Method For Optimal k')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.show()

# 4. Validate with Silhouette method
silhouette_scores = []

for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_preprocessed)
    labels = kmeans.labels_
    silhouette_scores.append(silhouette_score(X_preprocessed, labels))

# Plot Silhouette Scores
plt.figure(figsize=(8, 4))
plt.plot(range(2, 11), silhouette_scores, 'bo-', markersize=8)
plt.title('Silhouette Method For Optimal k')
plt.xlabel('Number of clusters')
plt.ylabel('Silhouette Score')
plt.show()

# 5. Apply K-means clustering with optimal number of clusters (e.g., 3)
optimal_clusters = 3  # Change based on the Elbow/Silhouette results
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
kmeans.fit(X_preprocessed)

# Add cluster labels to the original dataframe
df['Cluster'] = kmeans.labels_

# 6. PCA for 2D visualization of clusters
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_preprocessed)

plt.figure(figsize=(10, 6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['Cluster'], cmap='viridis', marker='o')
plt.title(f'2D PCA Plot of Clustering (k={optimal_clusters})')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.colorbar(label='Cluster')
plt.show()

from sklearn.preprocessing import LabelEncoder

# Convert 'ClusterType' to numerical labels for color mapping
label_encoder = LabelEncoder()
df['ClusterType_encoded'] = label_encoder.fit_transform(df['ClusterType'])

# Apply PCA for dimensionality reduction
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_preprocessed)

# Plot the PCA results, colored by ClusterType (encoded)
plt.figure(figsize=(10, 6))
scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['ClusterType_encoded'], cmap='viridis', marker='o')

# Add color bar and labels
plt.title('2D PCA Plot colored by ClusterType')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')

# Create a color bar with ClusterType labels
cbar = plt.colorbar(scatter, ticks=range(len(df['ClusterType'].unique())))
cbar.set_label('ClusterType')
cbar.set_ticklabels(label_encoder.classes_)  # Map colors to the original ClusterType labels

plt.show()
